
# here we import the libraries
import pandas as pd
from sklearn.model_selection import train_test_split


#  to print 5 rows columns
print(dataframe.head())

# prepare the data
x=dataframe.drop(columns="Age")
y=dataframe["Age"]

# split the data

x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.4,random_state=43)


# preprocess the data

from sklearn.preprocessing import StandardScaler


# initlize the scalar
scaler= StandardScaler()

# fir the data on the trainning data and transform the data

x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

# Train the model

from sklearn.neighbors import KNeighborsClassifier

# initlize the classifier with 3 neighbour

classifier = KNeighborsClassifier(n_neighbors=3)

# fir the classifier
classifier.fit(x_train_scaled,y_train)

# Make predictions

predictions=classifier.predict((x_test_scaled))

from sklearn.metrics import accuracy_score

# Calculate the accuracy of the predictions
accuracy = accuracy_score(y_test, predictions)
print(f'Accuracy: {accuracy}')


to build a machine learning model. I'll walk you through the steps of loading the 
dataset, preprocessing the data, training a model, and visualizing the results.

Steps 

1. Load the dataset 
2.Explore the dataset 
3. Preprocess the dataset 
4. Split the dataset 
5. Scale the dataset 
6. Train the model 
7. Make prediction 
8. Evaluate the model 


1. Load the Dataset
python
Copy code
import pandas as pd

# Load the dataset
data = pd.read_csv('/mnt/data/athlete_events.csv')

# Select specific columns
data = data[['Age', 'Height', 'Weight', 'Sport', 'Medal']]

# Display the first few rows of the dataset
print(data.head())
2. Preprocess the Data
Handle Missing Values: We'll drop rows with missing values for simplicity.
Encode Categorical Variables: We'll encode the 'Sport' column using one-hot encoding.
Create Target Variable: We'll create a binary target variable 'Medal_Won' indicating whether an athlete won a medal.
python
Copy code
# Handle missing values
data = data.dropna()

# Encode the 'Sport' column
data_encoded = pd.get_dummies(data, columns=['Sport'])

# Create the binary target variable 'Medal_Won'
data_encoded['Medal_Won'] = data_encoded['Medal'].notnull().astype(int)

# Drop the original 'Medal' column
data_encoded = data_encoded.drop(columns='Medal')

# Display the first few rows of the preprocessed dataset
print(data_encoded.head())
3. Select Features and Target
python
Copy code
# Select features and target
X = data_encoded.drop(columns='Medal_Won')
y = data_encoded['Medal_Won']
4. Split the Data
python
Copy code
from sklearn.model_selection import train_test_split

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
5. Scale the Data
python
Copy code
from sklearn.preprocessing import StandardScaler

# Initialize the scaler
scaler = StandardScaler()

# Fit the scaler on the training data and transform the training data
X_train_scaled = scaler.fit_transform(X_train)

# Transform the testing data
X_test_scaled = scaler.transform(X_test)
6. Train the Model
We'll use a Logistic Regression model for this example.

python
Copy code
from sklearn.linear_model import LogisticRegression

# Initialize the classifier
classifier = LogisticRegression()

# Fit the classifier on the scaled training data
classifier.fit(X_train_scaled, y_train)
7. Make Predictions
python
Copy code
# Make predictions on the scaled test data
predictions = classifier.predict(X_test_scaled)
8. Evaluate the Model
python
Copy code
from sklearn.metrics import accuracy_score, classification_report

# Calculate the accuracy of the predictions
accuracy = accuracy_score(y_test, predictions)
print(f'Accuracy: {accuracy}')

# Display a detailed classification report
print(classification_report(y_test, predictions))





........................................................................................................................
........................................................................................................................
                                        SIMPLE LINEAR REGRESSION
........................................................................................................................
........................................................................................................................
'''
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# Import the data set and analysing the data

dataset=pd.read_csv(r"C:\Users\HP\Downloads\Python CSV File\Salary_Data.csv")
x=dataset.iloc[:,:-1].values
y=dataset.iloc[:,:1].values

print(dataset.head())

# dataset analyze
#print(dataset.info)
#print(dataset.describe())
#print(dataset.columns)

cc= dataset.corr()
import seaborn as sns

sns.heatmap(cc, vmax=1, square= True, annot=True, cmap='coolwarm')

# split the dataset into train and test
xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=1/3,random_state=0)

# creating linear regression object and fitting it on our trainning set.

lr=LinearRegression()
lr.fit(xtrain,ytrain)

print(xtest)
print(ytest)

# predicting the test set result.

yprediction = lr.predict(xtest)
print("Prediction",yprediction)
#print("Ytest",ytest)

print("coefficient",lr.coef_)

print(lr.intercept_)

# predict

pred_salary = lr.predict([[6]])
print("predicted salary ",pred_salary)

print(lr.coef_)

print(lr.intercept_)
''' 
# visualizing the trainning test results

plt.scatter(xtrain,ytrain,color='red')
plt.plot(xtrain,lr.predict(xtrain),color='blue')
plt.xlabel("Experinces")
plt.ylabel("Salary")
plt.show()


#  visualising the test results

plt.scatter(xtest,ytest,color='red')
plt.plot(xtest,lr.predict(xtest),color='blue')

plt.xlabel("experinces")
plt.ylabel("salary")
plt.show()
'''
lr.predict([[4.2]])


....................................................................................................
.....................................................................................................


Project On Septal Length , Septal Weigth , Petal Length , Petal Weigth 



import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

#  2. Load the dataset
data=sns.load_dataset('iris')
print(data.head())

print(data.describe())
print(data.info())
data=data.dropna()
print(data)


 # visualizing the data
sns.pairplot(data,hue='species')
plt.show()

# Preprocess the data

data['species']=data['species'].astype('category').cat.codes

x=data.drop('species',axis=1)
y=data['species']
scaler= StandardScaler()
x_scaled = scaler.fit_transform(x)


#Split the dataset
x_train,x_test,y_train,y_test=train_test_split(x_scaled,y,test_size=0.2,random_state=42)


# Train the model
model=LogisticRegression()
model.fit(x_train,y_train)
y_pred=model.predict(x_test)

# Evaluate the model

accuracy=accuracy_score(x_test,y_pred)



















